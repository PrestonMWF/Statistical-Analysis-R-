---
title: "MScA Statistical Analysis 31007, Week 2 Assignment"
author: 'Mark Preston, Student ID: 12191901'
date: "April 3, 2018"
output: 
  html_document: 
    fig_height: 7
    fig_width: 9
---

***

##1 Generate uniformly distributed random numbers

###1.1 Use runif()

Function runif(N,a,b) simulates N pseudo-random numbers uniformly distributed on [a,b].


```{r running initial sample}
set.seed(15)
Sample <- runif(1000, 0, 1)
```

###1.2 Simulate Uniform Random Sample on [0,1] Using Random.org.

From Random.org you can download binary sequence using library `random`. This library is an interface to the web service of Random.org.

```{r installing and loading random package, warning=FALSE}
#install.packages("random")
library(random)

nFlips <- 1000
random_data <- randomNumbers(n = nFlips, min = 0, max = 1, col = 1,
                           base = 2, check = TRUE)
head(random_data, 10)
```

###1.3 Downloading data from Random.org directly

Since the `random` library worked, I didn't download any additional data from Random.org.

###1.4 Turning binary sequence to uniform random numbers

Turn your sequence of {0,1} into uniform random numbers, [0,1].

Create function that turns a sequence of zeros and ones of length n into decimal form.

```{r bits to integer function}
bitsToInt <- function(x) {
    packBits(rev(c(rep(FALSE, 32-length(x)%%32), as.logical(x))), "integer")
}

bitsToInt(c(1,1,1,1,1,0))
```

Turn the sequence of zeros and ones `dataFromRandom` of length 1000 into a matrix with 10 columns and 100 rows.

```{r vector into 10 x 100 matrix}
binary_matrix <- matrix(data = binary_matrix, ncol = 10)

head(binary_matrix)
```

Transform each row of the matrix into decimal format using `bitsToInt` and divide the numbers by 2 to the power 10 to make real numbers in [0,1].

```{r random data decimals}
decimal_sample <-apply(binary_matrix, 1, bitsToInt)/2^10

head(decimal_sample)
```

All numbers in `Decimal.Sample` are between 0 and 1. This is your own equivalent of the sample obtained by `runif()`.

```{r verifying range of decimal sample- numbers between 0 and 1}
range(decimal_sample)
```

***

##2 Test random number generators

###2.1 Test uniformity of distribution of both random number generators

####2.1.1 Using Sample generated by runif(): Analyze what was simulated by first looking at the histogram. What does the histogram tell you about the distribution? Is it consistent with the goal of simulation?

The goal of the simulation is to highlight how `runif` generates pseudo-random numbers and subsequently, observe their distribution to ensure they conform to RNG principles. Here, it appears that there isn't any identifiable pattern in the histogram and the distribution is generally uniform. 

```{r sample histogram}
library(ggplot2)
library(dplyr)

sample_df <- as.data.frame(Sample)

sample_histogram <- sample_df %>%
  mutate(cut = cut(Sample, breaks = 10, labels = c(.1, .2, .3, .4, .5,
                                                   .6, .7, .8, .9, 1))) %>%
  count(cut) %>%
  rename(counts = n) %>%
  mutate(density = counts / 1000 * 10)

sample_histogram %>%
  ggplot(aes(cut, counts)) +
  geom_col() +
  scale_y_continuous(breaks = seq(0, 120, 10)) +
  labs(title = "Sample of random numbers (length 1000) from runif plot- seems to conform to RNG principles")
```

There is some variation, as seen by the uneven counts and densities, but generally each break is close. Given this, it seems that the simulation is line with random principles, though some further testing might be revealing.

As a note, I prefer using `dplyr` and `ggplot` so the provided histogram numbers differ slightly from the ones here (due to how the samples get rounded). However, this doesn't change any of the underlying statistics dramatically. 

```{r histogram statistics}
library(kableExtra)

custom_kable <- function(x){
  kable(x, format = "html") %>%
  kable_styling(bootstrap_options = "striped")
}

custom_kable(sample_histogram)
```

The next chunk provides an estimate for the density mean and standard deviation for the histogram.

```{r histogram density mean and sd}
density_stats <- sample_histogram %>%
  summarise(density.mean = mean(density),
            density.sd = sd(density),
            upper.tail = density.mean + 1.96 * density.sd,
            lower.tail = density.mean - 1.96 * density.sd)

count_stats <- sample_histogram %>%
  summarise(counts.mean = mean(counts),
            counts.sd = sd(counts),
            upper.tail = counts.mean + 1.96 * counts.sd,
            lower.tail = counts.mean - 1.96 * counts.sd)

kable_left <- function(x){
  kable(x, format = "html") %>%
  kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
}

kable_left(density_stats)
```

####What does the graph tell you about the observed distribution?

The plot highlights that all the values are within the 95% confidence interval for the distribution. This lends further evidence to the claim that the numbers are truly randomized between 0 and 1 because the expectation would be a density of 1 per bin (evenly distributed). The confidence interval captures this by showing that despite some variation, each bin is within the acceptable 95% bounds.

```{r sample histogram with mean and confidence intervals}
sample_histogram %>%
  ggplot(aes(cut, counts)) +
  geom_col(fill = "lightgray") +
  scale_y_continuous(breaks = seq(0, 120, 10)) +
  geom_hline(yintercept = count_stats$counts.mean, colour = "#FF7F00", size = 1.3) +
  geom_hline(yintercept = count_stats$upper.tail, colour = "royalblue2",
             linetype = "dashed", size = 1.3) +
  geom_hline(yintercept = count_stats$lower.tail, colour = "royalblue2",
             linetype = "dashed", size = 1.3) +
  labs(title = "Plot shows that variables seem to conform to RNG principles- All values with in 95% confidence interval",
       subtitle = "Orange line represents mean (100) and both blue lines are upper and lower confidence bounds (118 and 82.3)",
       caption = "Data: 1000 random numbers generated using runif",
       x = NULL)
```

####What do you conclude about the estimated distribution from the moments?

A uniform distribution of random numbers between 0 and 1 should have theoretical values of .5 and .25 for moment one (expected mean) and moment two (expected variance). These are good starting points for comparing to the actual moments here because they allow a pure theoretical comparison to the sampled random numbers from `runif`. If the numbers are similiar, there is further evidence that the RNG simulates values correctly.

As seen, the actual compares well to the theoretical moments. The expected means are very close (about .016 difference) and the expected variance is close as well, though with a slightly larger difference (about .166). This variance was visiable in the random number plots given the bars for each break were not perfectly equal. As such, the larger deviation from the theoertical value here is not overly surprising. Overall though, all of this lends credibility to the RNG since the actual moments align well with the theoretical values.  

```{r sample moments}
kable_left(
  sample_df %>%
    summarise(first.moment = mean(Sample),
              theoretical.first = .5,
              second.moment = var(Sample),
              theoretical.second = .25)
)
```

####What do you think is the best way of estimating a uniform distribution over an unknown interval?

The best way to estimate the uniform distribution over an unknown interval is to assume it conforms to the expected values for the distribution. This means that it has a first moment of .5, a second moment of .25, and so on. Additionally, this means that the values will be about evenly distributed between 0 and 1 so any quantiles should be 0, .25, .5 (first moment), .75 and 1. All of these values provide sound estimations when working with an unknown uniform distribution interval.

```{r summary output for sample df}
sample_stats <- sample_df %>%
  summarise(sample.min = min(Sample),
            sample.25.Q = quantile(Sample, probs = .25),
            sample.mean = mean(Sample),
            sample.median = median(Sample),
            sample.75.Q = quantile(Sample, probs = .75),
            sample.max = max(Sample))

kable_left(sample_stats)
```

These estimation principles can be seen on display in a scatter plot below. The mean and quantiles are very close to the theoertical values. Another interesting feature with the grid here is seeing how each square has a reasonably similiar number of points in it but, without any discernable pattern.

```{r random number scatterplot}
sample_df %>%
  mutate(number = 1:1000) %>%
  ggplot(aes(number, Sample)) +
  geom_point() +
  geom_hline(yintercept = sample_stats$sample.mean, colour = "#FF7F00", 
             size = 1.3, alpha = .6) +
  geom_hline(yintercept = sample_stats$sample.25.Q, colour = "royalblue2",
             linetype = "dashed", size = 1.3, alpha = .6) +
  geom_hline(yintercept = sample_stats$sample.75.Q, colour = "royalblue2",
             linetype = "dashed", size = 1.3, alpha = .6) +
  labs(title = "Expected values can be used to estimate unknown uniform distribution- Sample values are all very close to theoretical",
       subtitle = "Orange line represents mean (.51) and both blue lines are 25th and 75th quantiles (.27 and .76)",
       caption = "Data: 1000 random numbers generated using runif")
```

####2.1.2 Repeat the same steps to test uniformity of the sample from Random.org

Below is the same treatment for the Random.org decimal sample. As with before, the goal is to assess if the Random.org data sample is correctly generating pseudo-random numbers by bserving their distribution to ensure they conform to RNG principles. 

The sample has more variation than the `runif` values but, this isn't too surprising since it's a smaller sample size. There doesn't appear to be any identifiable pattern in the histogram but, there is some wide variaition so some more testing wil help determine if it meets the uniform distribution standards.

```{r sample histogram for random.org}
random_df <- data.frame(Sample = decimal_sample)

sample_histogram <- random_df %>%
  mutate(cut = cut(Sample, breaks = 10, labels = c(.1, .2, .3, .4, .5,
                                                   .6, .7, .8, .9, 1))) %>%
  count(cut) %>%
  rename(counts = n) %>%
  mutate(density = counts / 1000 * 100)

sample_histogram %>%
  ggplot(aes(cut, counts)) +
  geom_col() +
  scale_y_continuous(breaks = seq(0, 120, 10)) +
  labs(title = "Sample of random numbers (length 100) from random.org plot")
```

There is some variation, as seen by the uneven counts and densities, and each break is variable ranging from .3 to 1.8. At a glance though, the density looks like it has an even mean (1).

```{r histogram statistics for random.org}
custom_kable(sample_histogram)
```

The next chunk provides an estimate for the density mean and standard deviation for the histogram. My intuition looks good here as the mean is indeed 1. Not surprisingly, there is a much larger standard deviaiton here when compared to the `runif` sample.

```{r histogram density mean and sd for random.org}
density_stats <- sample_histogram %>%
  summarise(density.mean = mean(density),
            density.sd = sd(density),
            upper.tail = density.mean + 1.96 * density.sd,
            lower.tail = density.mean - 1.96 * density.sd)

count_stats <- sample_histogram %>%
  summarise(counts.mean = mean(counts),
            counts.sd = sd(counts),
            upper.tail = counts.mean + 1.96 * counts.sd,
            lower.tail = counts.mean - 1.96 * counts.sd)

kable_left(density_stats)
```

####What does the graph tell you about the observed distribution?

The plot highlights that all the values are within the 95% confidence interval for the distribution. This lends further evidence to the claim that the numbers are truly randomized between 0 and 1 because the expectation would be a density of 1 per bin (evenly distributed). The confidence interval captures this by showing that despite some variation, each bin is within the acceptable 95% bounds.

```{r sample histogram with mean and confidence intervals for random.org}
sample_histogram %>%
  ggplot(aes(cut, counts)) +
  geom_col(fill = "lightgray") +
  scale_y_continuous(breaks = seq(0, 120, 10)) +
  geom_hline(yintercept = count_stats$counts.mean, colour = "#FF7F00", size = 1.3) +
  geom_hline(yintercept = count_stats$upper.tail, colour = "royalblue2",
             linetype = "dashed", size = 1.3) +
  geom_hline(yintercept = count_stats$lower.tail, colour = "royalblue2",
             linetype = "dashed", size = 1.3) +
  labs(title = "Plot shows that variables seem to conform to RNG principles- All values with in 95% confidence interval",
       subtitle = "Orange line represents mean (10) and both blue lines are upper and lower confidence bounds (1.28 and 18.7)",
       caption = "Data: 100 random numbers from Random.org converted to 0-1 range",
       x = NULL)
```

####What do you conclude about the estimated distribution from the moments?

As seen, the actual compares well to the theoretical moments. The expected means close (about .05 difference) and the expected variance is close as well, though with a slightly larger difference (about .167). This variance was visible in the random number plots given the bars for each break were not perfectly equal. As such, the larger deviation from the theoertical value here is not overly surprising. Overall though, all of this lends credibility to the Random.org numbers since the actual moments align well with the theoretical values.  

```{r sample moments for random.org}
kable_left(
  random_df %>%
    summarise(first.moment = mean(Sample),
              theoretical.first = .5,
              second.moment = var(Sample),
              theoretical.second = .25)
)
```


```{r random.org number scatterplot}
sample_stats <- random_df %>%
  summarise(sample.min = min(Sample),
            sample.25.Q = quantile(Sample, probs = .25),
            sample.mean = mean(Sample),
            sample.median = median(Sample),
            sample.75.Q = quantile(Sample, probs = .75),
            sample.max = max(Sample))

random_df %>%
  mutate(number = 1:100) %>%
  ggplot(aes(number, Sample)) +
  geom_point() +
  geom_hline(yintercept = sample_stats$sample.mean, colour = "#FF7F00", 
             size = 1.3, alpha = .6) +
  geom_hline(yintercept = sample_stats$sample.25.Q, colour = "royalblue2",
             linetype = "dashed", size = 1.3, alpha = .6) +
  geom_hline(yintercept = sample_stats$sample.75.Q, colour = "royalblue2",
             linetype = "dashed", size = 1.3, alpha = .6) +
  labs(title = "Ranodm.org scatterplot- values are more variable than the runif numbers",
       subtitle = "Orange line represents mean (.45) and both blue lines are 25th and 75th quantiles (.20 and .69)",
       caption = "Data: 100 random numbers from Random.org converted to 0-1 range")
```

###2.2 Test independence of the sequence of zeros and ones

####2.2.1 Turning point test

Turning point test is used to check if a sequence of numbers is i.i.d. (independent identically distributed).

The test is based on the number of turning points in the sequence.

The number of turning points is the number of maxima and minima in the series.

Let T be the number of turning points in a sample of length n large enough. The test is performed by `turning.point.test()` in the `randtests` package.

In this case, the p-value (.87) is very large and therefore, the null hypothesis is not rejected. With this, it can be concluded that the sample meets the Turning Point test randomness criteria. 

```{r random.org testing, message=FALSE, warning=FALSE}
#install.packages(randtests)
library(randtests)

turning.point.test(decimal_sample)
```

####2.2.2 Test frequency by Monobit test

To perform Monobit test you need to transform your {0,1} sample into {-1,1}.

Illustrate the test on the sequence simulated in the previous lecture.

We created the sequence of coin tosses. Erfc is the complimentary error function, a special function complimentary to error function erf=1-erfc.

Both functions can be easily calculated in R with the help of pnorm:

```{r monobit testing set-up}
monobit_random <- (random_data - .5) * 2

erf <- function(x) 2 * pnorm(x * sqrt(2)) - 1

erfc <- function(x) 2 * pnorm(x * sqrt(2), lower = FALSE)
```

To test if sequence Ri check the value erfc(S), review if the P-value or erfc(S) is less or equal than 0.01. if so, the sequence fails the test. the Random.org data passes as seen below.

```{r monobit testing}
erfc(abs(sum(monobit_random)/sqrt(2 * nFlips)))
```

Each run can be checked as well. As seen, all null hypotheses are rejected.

```{r erfc plotting test}
erfc_df <- data.frame(
  test = 1:20,
  erfc.p.value = erfc(abs(apply(matrix(monobit_random, ncol = 50), 1, sum))/sqrt(2 * 50))
)

erfc_df %>%
  mutate(significance.threshold = ifelse(erfc.p.value <= .01, 
                                         "non-random", "random")) %>%
  ggplot(aes(test, erfc.p.value, colour = significance.threshold)) +
  geom_point(size = 3) +
  geom_hline(yintercept = 0.01, colour = "#FF7F00", 
             size = 1.3, alpha = .3) +
  scale_color_manual(values = c("royalblue2")) +
  labs(title = "All erfc tests are above p-value threshold, though point 20 is close")
```

***

##3 Invent a random number generator

Think about possible sources of true or pseudo-random sequences of {0,1} and choose one.

Conduct the tests described in the previous section.

###Description of your random number generator

My random number generator focuses on the stock price of banking giant Goldman Sachs. The project aims to assess if the stock variations are governed by randomness. To do so, I obtained a data set with the firm's stock price from 2006 to the end of 2015. Specifically, I chose to focus on the most recent year, 2015, which has 252 entries. The set has prices for open, close, minimum, and maximum, of which I chose to focus on the opening price each day. As such, the anlaysis reviews the opening Goldman price for all of 2015.

Going in, the analysis has a few shortcomings. Notably, the date range is fairly arbitrary having selected a specific year. Without any proper finance background, I also don't have a strong rationale or explanation for picking open over the other prices. That said, the analysis is novel and should be an interesting dive into the variations of financial market data. Any findings are at best perfunctory but, I'm interested in attempting to gauge randmomness in a notoriously random domain.

```{r goldman sachs stock price data 2006-2015 load}
goldman <- read.csv("GS.csv", stringsAsFactors = F)
```

###Generated sequence

The opening prices aren't conveniently scaled for a uniform distribution. As such, I needed to develop a function to scale the price range from its current form to between 0 and 1. As seen below, `scale_range` performs this work and transforms the variable into a form that is useable for the randomness testing. From there, I also pared down the data set to include only 2015 entries for `Open` and `Scaled.open`.  

```{r generating goldman sequence data}
scale_range <- function(x){
  (x - min(x)) / (max(x) - min(x))
}

goldman <- goldman %>%
  mutate(Date = as.Date(Date),
         date.range = grepl(pattern = "2015", Date),
         Scaled.open = scale_range(Open)) %>%
  filter(date.range == T) %>%
  select(Date, Open, Scaled.open)
```

Before diving into the randomness work, I thought I would visualize the price data to get a feel for how it moved throughout 2015. At first glance, the line doesn't look very random as there seems to be patterns in the movement. In contrast, a random set looks more erractic, like a nosiy stereo wave, without any patterned ups and downs. This can be further verified during the next few tests though.

```{r goldman 2015 line plot}
goldman %>%
  ggplot(aes(Date, Open)) +
  geom_line(size = 1.3, colour = "royalblue2") +
  scale_y_continuous(breaks = seq(170, 220, 5)) +
  geom_hline(yintercept = mean(goldman$Open), size = 1.3,
                               colour = "#FF7F00", alpha = .3) +
  labs(title = "Goldman Sachs opening stock price, Dec. 2015 to Jan. 2016",
       subtitle = "Mean opening price was 193 (orange line)",
       x = NULL)
```

###Results of the uniformity test

The intial results do not look random. There seems to be a pattern in the sample where price rises and then falls. Compared to the `runif` and Random.org data, both of which were verified using randomness testing, this looks much different.

```{r goldman uniformity test}
goldman_histogram <- goldman %>%
  ggplot(aes(Scaled.open, ..density..)) +
  geom_histogram(fill = "lightgray", boundary = .1, binwidth = .02) +
  scale_x_continuous(breaks = seq(.5, 1, .02)) +
  labs(title = "Scaled Goldman Sachs opening stock price, Dec. 2015 to Jan. 2016",
       subtitle = "Data does not appear to be random- price rises and falls with some pattern")

goldman_histogram
```

The density breaks can be extracted from the plot and analyzed for variation and range. Here, there is mounting evidence that the data is not random. The density mean is well over one given the range is from 1.59 to 8.33.

```{r histogram statistics for random.org}
sample_histogram <- data.frame(
  bin = layer_data(goldman_histogram)$x,
  counts = layer_data(goldman_histogram)$count,
  density = layer_data(goldman_histogram)$density
)

custom_kable(sample_histogram)
```

The next chunk provides an estimate for the density mean and standard deviation for the goldman histogram. This further solidifies that the data does not appear to be random. the standard deviation (1.92) is well above the theoertical value for a uniform distribution. Further, the upper tail appears to be under one of the bin densities.

```{r histogram density mean and sd for random.org}
density_stats <- sample_histogram %>%
  summarise(density.mean = mean(density),
            density.sd = sd(density),
            upper.tail = density.mean + 1.96 * density.sd,
            lower.tail = density.mean - 1.96 * density.sd)

count_stats <- sample_histogram %>%
  summarise(counts.mean = mean(counts),
            counts.sd = sd(counts),
            upper.tail = counts.mean + 1.96 * counts.sd,
            lower.tail = counts.mean - 1.96 * counts.sd)

kable_left(density_stats)
```

The plot highlights that all the values are not within the 95% confidence interval for the distribution. This lends further evidence to the claim that the numbers are not randomized.

```{r sample histogram with mean and confidence intervals for random.org}
sample_histogram %>%
  ggplot(aes(bin, counts)) +
  geom_col(fill = "lightgray") +
  geom_hline(yintercept = count_stats$counts.mean, colour = "#FF7F00", size = 1.3) +
  geom_hline(yintercept = count_stats$upper.tail, colour = "royalblue2",
             linetype = "dashed", size = 1.3) +
  geom_hline(yintercept = count_stats$lower.tail, colour = "royalblue2",
             linetype = "dashed", size = 1.3) +
  labs(title = "Plot shows that Scaled.open does not seem to conform to RNG principles- values broach 95% confidence interval",
       subtitle = "Orange line represents mean (21) and both blue lines are upper and lower confidence bounds (2.07 and 39.93)",
       x = NULL)
```

To continue the last part of the uniformity test, the theoertical quantiles of the uniform distirbution can be compared here. Of course, it seems like a foregone conclusion that the sample is not random but, it's important to be thorough and do all the testing. As expected, the results further accentuate that the sample does not appear to be random. Both moments have large differences.

```{r sample moments for random.org}
kable_left(
  goldman %>%
    summarise(first.moment = mean(Scaled.open),
              theoretical.first = .5,
              second.moment = var(Scaled.open),
              theoretical.second = .25)
)
```

###Results of the frequency test

The results so far seem convincingly in favour of the Goldman opening pricebeing non-random. With the Monobit testing, another level of confidence can be added. With a p-value of essentially zero, the null hypothesis is rejected and the alternative hypothesis, that the sample is non-random, is accepted.

```{r monobit testing set-up}
kable_left(goldman %>%
  mutate(monobit.goldman = (Scaled.open - .5) * 2) %>%
  summarise(goldman.erfc = erfc(abs(sum(monobit_goldman)/sqrt(2 * nrow(goldman)))))
)
```

###Results of the turning point test

The testing isn't really in doubt at this point but, the turning point test is included as well. The p-value for the turning test is extremely small, which is exactly in line with the other testing. With the final test, it seems very likely that the sample is not random. The evidence is clear and the opening price for banking stalwart Goldman Sachs appears non-random. All that's left to do is decipher the price movement's non-randomness and the real money will start flowing in.

```{r goldman turning point, message=FALSE, warning=FALSE}
turning.point.test(goldman$Scaled.open)
```

***

##4 Monte Carlo Method

###4.1 Scratch off quote of the day: fuction download

```{r loading monte carlo simulation}
load("ScratchOffMonteCarlo.rda")
```

###4.2 Simulate pseudo-random poins [x,y] on [0,100] x [0,100]

Select a number of points for `nSample`.

Simulate a sample of length `2*nSample` from uniform distribution on [0,100] and turn it into a (nSample x 2) matrix.

Use a seed of your choice `my.seed`.

```{r monte carlo set up}
set.seed(1017)

nSample <- 25000

xy <- runif(2 * nSample, 0, 100)

xy <- matrix(xy, ncol = 2)

head(xy)
```

My first run used 25,000 samples and a seed of 1017; this scratched off 91.45% of the yellow points. This was more than enough to read the message: "The purpose of models is not to fit the data but to sharpen the questions", which was wisely uttered by Samuel Karlin.

```{r monte carlo scratch}
ScratchOffMonteCarlo(xy)
```

####By changing nSample and my.seed try to make the quote of the day readable with minimum sample size. What percent you needed to scratch off to make the quote readable?

To do this with some speed, I rolled the sampling and simulation plot function into one and tried a few permutations of sample size and seed. The first combination I tested was a sample size of 1000 with a seed of 1. Only about 9.55% percent was scratched off, which is not enough to even begin to read the message.

```{r custom monte carlo}
fast_monte <- function(sample.n, seed){
  set.seed(seed)
  nSample <- sample.n
  xy <- runif(2 * nSample, 0, 100)
  xy <- matrix(xy, ncol = 2)
  ScratchOffMonteCarlo(xy)
}

fast_monte(1000, 1)
```

The second got closer sith a combination of 10,000 and a seed of 1000. As a note, the seeds seems to change the open percentage around the margins (maybe a percent up or down dependent on number) but the sample size drives the major jumps. The message here is still unreadable at 63.41%.

```{r custom monte carlo 2}
fast_monte(10000, 1000)
```

With some further testing, it looks like at around 75% open, the message becomes legible. Even at 75.37% open though, it's only just clear enough to read.

```{r custom monte carlo 3}
fast_monte(14000, 1)
```

###4.3 Simulate quasi-random poins [x,y] on [0,100] x [0,100]

```{r quasi-random simulation}

```



***

##References

***

Stock Data: Stock prices of top banks throughout the financial crisis to early 2016

https://www.kaggle.com/rohan8594/stock-data/data

The stock data I used for my random number generator was downloaded from Kaggle. It contains data on Goldman Sachs stock price.

***
