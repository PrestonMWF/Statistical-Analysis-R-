---
title: "Experiment Analyzing Trajectories from Multiple Coin Tosses"
author: 'Mark Preston, Student ID: 12191901'
date: "March 28, 2018"
output: 
  html_document: 
    fig_height: 7
    fig_width: 10
---

***

##1. Convergence of probability of tail to 0.5

Check that frequency of "Tails" (outcome equals 1) converges to 0.5 as the number of tosses grows

####What does this say about fairness of the coin?

A coin with .5 probability for both heads and tails is fair. This means that each side has an equal probability of coming up during a flip. If the outcomes converge to .5 as the number of tosses goes up, this fairness assumption can be verified.

Use the following seed for reproducibility:

set.seed(12345);

Set the number of flips to 100,000.

###Code explained

The chunk below sets the number of flips for the simulation to 100,000. This object will be used in the next chunk to run the actual flip simulation.

```{r setting number of flips}
nFlips<-100000
```

###Code explained

The code below runs the coin flip simulation 100,000 times and then plots the results. Before the actual simulation is run, a seed is set for the exercise. Due to the randomness of such a large simulation, the seed makes the event reproducible by setting a specific number associated with the work. As such, this ensure the exact results can be obtained more than once.

Following that, the actual simulation is conducted by sampling either 1 or 0 with replacement 100,000 times. the result is stored as a numeric vector in the Flips object. Trajectory takes the cumulative sum of the Flips object. A cumulative sum works by adding the numbers as they come up, here 1 and 0. The idea is the trajectory with a fair coin will eventually even out to the expected mean, which is .5 here. This number is the frequency. It's derived by dividing the number of flips by the cumulative sum so the coin toss progress can be followed.

The visualization is produced using base R `plot` with accompanying lines to highlight zero. The graph limits have been changed to only fit the first 4000 flips as well.

###Graph interpretation

After the simulation, it can be seen that the frequency of heads and tails fluctuates in the short term, the first 50 of the sample length, and evens out in the long term. The freq objects divides the number of the trial by the simulation's cumulative sum at that time, so it's not surprising to see it being volatile to begin before evening out. That said, it doesn't fall exactly in line with .5, which would be the expected end point. However, it is close and a table of the heads and tails reveals both sides being nearly even (Heads: 49,916 & Tails: 50,084). Given this, the graph highlights that after the first 4,000 flips, the frequency of heads to tails is just above .5 with tails being slightly ahead. 

```{r coin simulation and visualization}
set.seed(12345)
Flips<-sample(0:1,nFlips,repl=T)
Trajectory<-cumsum(Flips) 
freq<-Trajectory/(1:nFlips)
plot(1:length(freq),freq, ylim=c(.4,1),type="l",ylab="Frequency",xlab="Sample Length")
lines(c(0,nFlips),c(.5,.5))
plot(1:4000,freq[1:4000], ylim=c(.4,1),type="l",ylab="Frequency",xlab="Sample Length") 
lines(c(0,4000),c(.5,.5))

#number of heads and tails- not perfectly even, though close
table(Flips)
```

***

##2. Check your intuition about random walks

###2.1. One trajectory

Create trajectory of wealth in a game which either pays 1 dollar with probability 0.5 or results in loss of 1 dollar on each step.

Assume that the game is played 1,000,000 times.

Use the same seed.

Increase the number of flips to 1,000,000.

###Code explained

Once again, this chunk sets up the simulation, this time with 1 million flips. Additionally, the trajectory is included by turning heads and tails into either a 1 or -1 value. These represent the win and loss propositions for the simulation.

```{r million flip simulation}
nFlips<-1000000
set.seed(12345)
Flips<-(sample(0:1,nFlips,repl=T)-.5)*2

#reviewing Flips values
table(Flips)
```

###Check your intuition by answering questions before calculation:

####How much do you expect the trajectory of wealth to deviate from zero

I would expect the wealth to be around zero, though not exactly on. The previous simulation with 100,000 flips rendered a close division of heads and tails (Heads was 84 under the difference of zero). My guess would be the new simulation would be proportionally around the same over zero but, by aggregate larger (maybe around 1,000, derived from taking 84 * 10). 

####How long do you expect it to stay on one side above or below zero?

I would expect it to be reasonably even up and down corresponding to separate uneven runs of heads and tails. As such, the plot would be a wavy line bisecting zero a few times. Putting a proportion on it, I would say it should be about 50% over or under zero. This reflects what the flip proportions should eventually even out to.

###Code explained

Much like before,the trajectory (cumulative sum of the new win loss values) is stored as an object and subsequently plotted.

```{r plotting million flip simulation}
oneTrajectory<-cumsum(Flips)
plot(oneTrajectory, ylim=c(-1000,1000),type="l")
lines(c(0,nFlips),c(0,0))
```

####How do the observations match your prior expectations? Find at least one alternative way of simulating variable Flips and repeat the experiment multiple times.

I've rolled the personal simulation and observations into one question. The visualization above shows my intuition was reasonably good on how close the trajectory would end to zero. There were +67 heads, which is in line with the first simulation. However, the percent over zero here looks large (maybe 80% to 85% as a guess), which is out of sync with my intuition. I thought this might have been a bit smaller but, given it's only one example of the simulation, a few more might help illuminate if this variability is reasonable to expect from the trajectory.

For this, the simulation I've set up uses `rbinom`. Basically, I've run the simulation 9 times consecutively and stored the results in a data frame to be plotted and reviewed at once. From there, I've added the trajectory for the simulations by creating a pay out variable corresponding to the dollar value of each flip (1 dollar for heads, -1 dollar for tails) and then taking the cumulative sum for each run. With the data for the simulations saved, the results can be verified and checked against my intuition next.

```{r setting up and running simulation, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(knitr)
library(kableExtra)

#prefered plot aesethic
theme_set(
  theme_bw()
)

flip_n <- 9000000

set.seed(1017)
game_simulation <- data.frame(
  flip.simulation = rep(c("one", "two", "three", "four", "five", "six",
                          "seven", "eight", "nine")),
  game.number = 1:9000000,
  outcome = rbinom(n = flip_n, size = 1, prob = .5)
)

game_simulation <- game_simulation %>%
  group_by(flip.simulation) %>%
  mutate(pay.out = case_when(
    outcome == 1 ~ 1,
    outcome == 0 ~ -1),
    trajectory = cumsum(pay.out)) %>%
  ungroup() %>%
  mutate(flip.simulation = factor(flip.simulation, 
                             levels = c("one", "two", "three", 
                                        "four", "five", "six",
                                        "seven", "eight", "nine")))

kable(head(game_simulation, 9), format = "html") %>%
  kable_styling(bootstrap_options = "striped")
```

The final trajectories are all under 2000 dollars with the largest being 1946. The smallest here is close to zero (98). Only two of the nine simulations are under zero. All of these are generally in line with my initial intuitions on where the final trajectories would be considering 1 million flips.

```{r reviewing simulation results- final trajectory}
kable(game_simulation %>%
  filter(game.number >= 8999992) %>%
  group_by(flip.simulation) %>%
  summarise(final.trajectory = trajectory) %>%
  arrange(desc(final.trajectory)), format = "html") %>%
  kable_styling(bootstrap_options = "striped")
```

Once again though, my intuition about how much of the trajectory would be over zero was seemingly inaccurate. Only one of the simulations has a trajectory where there is a reasonably even split above and below zero (simulation two, 54% above and 46% below). I originally thought there might be around 50% above or below the line; 8 out of 9 simulations are outside this split (I'm counting the 54% above as close enough, providing some leeway). In fact, there are three runs that have trajectories which stayed above zero for over 95% of the simulation.

```{r reviewing simulation results- percentage over/under zero}
kable(game_simulation %>%
  filter(trajectory > 0) %>%
  group_by(flip.simulation) %>%
  count() %>%
  summarise(trajectory.over.zero.percent = round(n / 1000000 * 100, 2),
            under.zero.percent = round(100 - trajectory.over.zero.percent, 2)) %>%
  arrange(desc(trajectory.over.zero.percent)), format = "html") %>%
  kable_styling(bootstrap_options = "striped")
```

The plot below highlights each simulation trajectory. What's interesting is that every simulation ends within 2000 of zero but, many of them still stay either above or below zero for most of the simulation. Simulation four essentially does not cross zero, outside of the first few flips. The lines do not bisect zero as much as I would have thought, nor was my intuition on how much time the trajectory spends above or below zero well calibrated. Given this, the observations matched my expectations well enough for the amount of heads versus tails but, seem to be off in terms of trajectory percent. That said, there isn't that many simulations included so there could be some variance in the result.

```{r simulation visualization, cache=TRUE, fig.width=11}
game_simulation %>%
  ggplot(aes(game.number, trajectory, colour = flip.simulation)) +
  geom_line() +
  facet_wrap(facets = "flip.simulation") +
  geom_hline(yintercept = 0, colour = "red") +
  theme(legend.position = "none") +
  labs(title = "Nine simulations of 1 million coin flips alongside expected pay out (1 head = 1$ & 1 tail = -1$)",
       subtitle = "All runs have differing trajectories and none end up at exactly zero (seven over, two below) -- All are within $2,000 of zero though")
```

###2.2. Multiple trajectories

####What do you expect the probabilities of the following events to be?

- Probability of difference between heads and tails is less than 5 with 500 flips?

I would expect this to be fairly high given this area would be in the largest portion of the distribution (between an upper and lower bound of 255 and 245 given mean 250, or even heads and tails). This assumes the distributions are approximately normal. As such, I will assume around 30% probability of getting less than a difference of 5 with 500 flips.

- Probability of difference between heads and tails is greater than 25 with 500 flips?

I would expect this to be low given this area comprises the two tails of the distribution  above 275 and below 225 (given mean 250, or even heads and tails). This assumes the distributions are approximately normal. As such, I will assume around 10% probability of getting greater than a difference of 25 with 500 flips.

###Code explained

This chunk spreads 1 million flips into 2000 unique simulations, each with 500 flips. Building on this, the matrix is transposed so the simulations are rows instead of columns. Apply is then used in conjunction with cumulative sum (1 indicates the operation is being done on a row) so that each simulation row slowly aggregates the final results until the last column, 500, has each final trajectory. The data is stored in a matrix, with each row as a unique simulation and each column the flip number up to 500 (although subsequently I put it into data frame to analyze and plot).

```{r 2000 random walks with 500 flips}
Trajectory2000 <- t(apply(matrix(Flips, ncol = 500), 1, cumsum))

random_walks <- data.frame(
  flip.simulation = 1:2000,
  trajectory = Trajectory2000[,500]
)
```

My intuition was slightly off here given there were 18% of walks with a difference of less than 5.

```{r random walk results- less than 5 table}
kable(random_walks %>%
  filter(trajectory > -5 & trajectory < 5) %>%
  count() %>%
  summarise(less.than.five = n / 2000 * 100), format = "html") %>%
  kable_styling(bootstrap_options = "striped", full_width = F , position = "left")
```

The histogram shows my normal distribution assumption was incorrect, which might explain an amount of the difference. However, it's generally just less than I was expecting.

```{r random walk results- less than 5 histogram, message=FALSE}
random_walks %>%
  ggplot(aes(trajectory)) +
  geom_histogram(fill = "lightgray") +
  geom_vline(xintercept = -5, linetype = "dashed", 
             colour = "royalblue2", size = 1.5) +
  geom_vline(xintercept = 5, linetype = "dashed", 
             colour = "royalblue2", size = 1.5) +
  scale_x_continuous(breaks = seq(-100, 100, 10)) +
labs(title = "Portion of random walks between 5 and -5 is 18% (2000 simulations with 500 flips each)")
```

My intuition was very off for the second estimation given there were 25% of walks with a difference of greater than 25.

```{r random walk results- greater than 25 table}
kable(random_walks %>%
  filter(trajectory > 25 | trajectory < -25) %>%
  count() %>%
  summarise(greater.than.twenty.five = n / 2000 * 100), format = "html") %>%
  kable_styling(bootstrap_options = "striped", full_width = F , position = "left")
```

The histogram shows my normal distribution assumption was incorrect, which might explain an amount of the difference. The tails past 25 on each side are much larger than I anticipated, which means my intuition underestimated the actual differences.

```{r random walk results- greater than 25 histogram, message=FALSE}
random_walks %>%
  ggplot(aes(trajectory)) +
  geom_histogram(fill = "lightgray") +
  geom_vline(xintercept = -25, linetype = "dashed", 
             colour = "royalblue2", size = 1.5) +
  geom_vline(xintercept = 25, linetype = "dashed", 
             colour = "royalblue2", size = 1.5) +
  scale_x_continuous(breaks = seq(-100, 100, 25)) +
labs(title = "Portion of random walks greater than 25 or -25 is 25% (2000 simulations with 500 flips each)")
```

In both cases, because I assumed a normal distribution my intuition was not especially close. The 5 question was too generous and the 25 question was too conservative. I thought that the 5 would be much higher than 25, when in fact 25 had 25% and 5 had 18% (a difference of 7%).

###2.3. Time on one side

####How long do you expect trajectory of random walk to spend on one side from zero, below or above? Interpret the results- was your intuition correct?

I think that the proportion for all the walks will be around 50%. Intuitively, with a large sample the average above or below should be about even. To expand on this, a portion of the 2000 simulations should be well above and some well below zero. However, they should even out to around 50% over a large enough sample. The previous example with 1 million flips only included 9 simulations. 9 isn't very many, despite having 9 million total flips. The difference here, as opposed to 1 million flips over 9 simulations, is that the 1 million flips are distributed between 2000 runs, so there is a higher likelihood they converge to being about 50% above and below zero.

###Code explained

This chunk puts the values over zero into a data frame. The final value is derived using the custom function to sum values over zero from rows (each, a unique simulation) in the trajectory matrix. The result can then be divided by the total number of flips, 500, to see what proportion was above or below zero. For example, if the final sum is 400, which indicates there was 400 values over zero, then the final proportion is 80% (400 / 500 * 100).

```{r random walks - percentage over/under zero}
random_walks <- random_walks %>%
  mutate(over.zero = apply(Trajectory2000, 1, function(z) sum(z>0)),
         proportion = over.zero / 500 * 100)
```

It seems my intuition was reasonable here. The mean proportional difference is about 49%. The sample size seems to even out the above and below zero.

```{r random walks - percentage over/under zero review}
kable(random_walks %>%
        summarise(random.walk.min = min(proportion),
            random.walk.max = max(proportion),
            random.walk.mean = mean(proportion),
            random.walk.median = median(proportion)), format = "html") %>% 
  kable_styling(bootstrap_options = "striped")
```

What's interesting though is that despite the mean being more or less even, there are many simulations where the trajectory was well above or well below zero. In fact, the two most frequent proportions are 0 (65) and 100 (36). The other most frequent values are also very close to either 0 or 100. This means that a large number of simulations have trajectories that are either nearly, if not all, above or below zero.

```{r random walks mode}
rw_mode <- random_walks %>%
  count(proportion, sort = T) %>%
  rename(count = n) %>%
  filter(count > 12)

kable(rw_mode, format = "html") %>%
  kable_styling(bootstrap_options = "striped", full_width = F, position = "center")
```

###Explain the observed distribution

While this seems like an unexpected distribution, it conforms to my initial explanation. That said, I had expected the histogram to be an approximately normal distribution. However, this seems to make sense given the proportions should even out to 50%. With this, each limit, 0 and 100, have to be reasonably equal and move slowly into the middle. At first glance, this seems counterintuitive with two very populated tails and a dip into the centre of the distribution. But it's more or less an inverse normal distribution. Building on this, since the scale is between 0 and 100, with the expected mean at around 50, the distribution has to balance to this value. For this to work, there has to be heavy tails at 0 and 100. As such, the results conform to my initial intuition but, the distribution looks different than I would have thought.

###Code explained

The chunk below makes the proportional histogram. I've added in a line for the mean to further highlight the split above and below the 50% proportion (despite it being 49, it's close).

```{r random walks proportion over/under zero histogram, message=FALSE}
random_walks %>%
  ggplot(aes(proportion, ..density..)) +
  geom_histogram(fill = "lightgray") +
  geom_density(colour = "#EE6363", size = 1.2) +
  scale_x_continuous(breaks = seq(0, 100, 25)) +
  geom_vline(xintercept = 49, linetype = "dashed", 
             colour = "royalblue2", size = 1.5) +
  labs(title = "Portion of random walks finishing over 50% (2000 simulations with 500 flips each)",
       subtitle = "Blue line is mean (49% above zero)")
```

As an alternative way to view this distribution, proportion can be transformed to a -50 to 50 scale, given above and below zero, and then plotted. The ordered bar chart, which has been smoothed to convey the area of each trajectory, better accentuates how both proportions even out after 2000 simulations.

```{r random walks proportion over/under zero ordered bar plot}
random_walks %>%
  mutate(proportion = proportion - 50,
         trajectory.finish = ifelse(proportion > 0, "above.zero", "below.zero"),
         flip.simulation = as.numeric(reorder(flip.simulation, proportion))) %>%
  ggplot(aes(flip.simulation, proportion, 
             fill = trajectory.finish, colour = trajectory.finish)) +
  geom_col() +
  geom_hline(yintercept = -1, linetype = "dashed", 
             colour = "royalblue2", size = 1.5) +
  labs(title = "Portion of random walks finishing above 50% (2000 simulations with 500 flips each)",
       subtitle = "Scaled so zero is 50% and increments above are plus and minus; Blue line is mean (-1, or 49% above zero)")
```

###Search for the name of the law that we are observing on the last histogram

This is The Arcsine Law. The law outlines how a large fraction of simulation coin flip paths leave one side (heads or tails here) in the lead almost all the time. It also outlines how in very few cases the game trajectory changes sides by crossing the x-axis. With this in mind, Arcsine Law highlights that the points most likely to occur will arise on either tail of the distribution (0 and 100 here). This is on clear display in the histogram and bar plot. As aforementioned, the outcome seems intuitive enough with the proportion mean being about 50 but, it materializes in an unexpected way owing the Arcsine Law.

I had originally thought the distribution would be a result of The Law of Large Numbers, which states that as the number of trials in a simulation go up, the results should converge on the expected value (mean in this case). However, this explains the tendency towards a certain value over the long run and not the variable behaviour to be above or below zero. As such, these are two distinct ideas (law of large number vs law of large leads).

To show this law in the experiment, a line plot of the 2000 simulations converging to the expected trajectory mean of zero is displayed below. Each trajectory line is included alongside their mean (0.18, or about 0). The line plot below highlights how some simulations are really high or low but, on average, they combine to the expected mean. Of interest, features of the Arcsine are evident as well with certain lines starting, and staying, entirely above or below zero.

```{r 2000 x 500 simulation visualization, cache=TRUE, message=FALSE, fig.width=11}
library(reshape2)

trajectory2000 <- data.frame(t(Trajectory2000))

trajectory2000 <- melt(trajectory2000, variable.name = "flip.simulation") %>%
  mutate(flip.number = rep(1:500, time = 2000))

trajectory2000 %>%
  ggplot(aes(flip.number, value, colour = flip.simulation)) +
  geom_line(size = 1, alpha = .3) +
  theme(legend.position = "none") +
  geom_hline(yintercept = 0, colour = "red", size = 1.2) +
  theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank()) +
  labs(title = "2000 simulations each with 500 flips alongside expected pay out for run (1 head = 1$ & 1 tail = -1$)",
       subtitle = "Runs have differing trajectories but mean is about 0; This demonstrates the Law of Large Numbers (as n increases, sample moves towards E[Y])",
       y = "trajectory")
```

***

###References

***

####The Excess of Heads over Tails, Long Leads, and the Arcsine Law

http://www.math.unl.edu/~sdunbar1/ProbabilityTheory/Lessons/BernoulliTrials/ExcessHeads/excessheads.shtml

***